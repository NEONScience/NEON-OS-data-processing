dps <- list.dirs(paste(gitpath, "NEON-quick-start-guides", sep="/"))
dps <- dps[grep("DP[0-4]{1}[.]", dps)]
tlengths <- character()
for(i in 1:length(dps)) {
# pull out all the table joining tables
tpath <- paste(dps[i], "Table.joining.md", sep="/")
tmd <- try(suppressWarnings(readLines(tpath)), silent=TRUE)
if(class(tmd)=="try-error") {
next
}
if(length(tmd)==0) {
next
}
if(identical(tmd, "")) {
next
}
# download data to get table names
dpid <- regmatches(dps[i], regexpr('DP[0-4]{1}[.][0-9]{5}[.]00[0-2]', dps[i]))
dat <- loadByProduct(dpid, site=c('HARV', 'ARIK', 'NIWO', 'SUGG'),
startdate='2019-10', enddate='2019-12',
package='expanded',
check.size=F, token=Sys.getenv('NEON_TOKEN'))
# subset to just data tables
dat.tab <- grep('variables|validation|categorical|readme|issue', names(dat), invert=T, value=T)
# if only one data table, print and move on
if(length(dat.tab)==1) {
print(dat.tab)
next
}
# get table types from neonUtilities
ttypes <- table_types[which(table_types$tableName %in% dat.tab), c('tableName', 'tableType')]
# pull QSG data out of markdown
l <- lapply(tmd, FUN=function(x) {
y <- unlist(strsplit(x, "|", fixed=TRUE))
y <- gsub("\\", y, replacement="", fixed=TRUE)
return(y)
})
# convert data to table form
tab <- do.call(rbind.data.frame, l)
tab <- tab[-c(1,2),-1]
if(ncol(tab)==3) {
tab$JoinByTable2 <- tab[,3]
}
names(tab) <- c("Table1","Table2","JoinByTable1","JoinByTable2")
# if a table is in the QSG but not in download, print warning
if(!all(union(tab$Table1, tab$Table2) %in% dat.tab)) {
mis <- setdiff(union(tab$Table1, tab$Table2), dat.tab)
print(paste('Tables ', paste(mis, sep=', '), ' not found in downloaded data.', sep=''))
}
# check for site-all, lab-all, and lab-current tables
if(length(which(ttypes$tableType %in% c('site-all','lab-all','lab-current')))>0) {
nomerge <- dat.tab[which(dat.tab %in%
ttypes$tableName[which(ttypes$tableType %in%
c('site-all',
'lab-all',
'lab-current'))])]
dat.tab <- dat.tab[!dat.tab %in% nomerge]
}
# combinations of tables
dat.c <- data.frame(t(combn(dat.tab, 2)))
# is each combination in the QSG?
ind <- numeric()
for(j in 1:nrow(dat.c)) {
if(paste(dat.c[j,], collapse='.') %in% paste(tab$Table1, tab$Table2, sep='.') |
paste(dat.c[j,], collapse='.') %in% paste(tab$Table2, tab$Table1, sep='.')) {
ind <- c(ind, j)
}
}
# remove pairs accounted for
dat.sub <- dat.c[-ind,]
names(dat.sub) <- c('Table1', 'Table2')
# append to table
tjt <- data.table::rbindlist(list(tab, dat.sub), fill=T)
# check need for 4 columns
if(identical(tjt$JoinByTable1,tjt$JoinByTable2)) {
tjt <- tjt[,c('Table1', 'Table2', 'JoinByTable1')]
}
# append lab and site-all tables
if(!is.null(nomerge)) {
notrec <- data.frame(cbind(nomerge,
'Join not recommended. Data resolution does not match other tables.'))
names(notrec) <- c('Table1', 'JoinByTable1')
tjt <- data.table::rbindlist(list(tjt, notrec), fill=T)
}
# write back to markdown
if(ncol(tjt)==3) {
cat("|Table 1|Table 2|Join by field(s)|\n", file=tpath)
cat("|------------------------|------------------------|-------------------------------|\n",
file=tpath, append=T)
cat(apply(tjt, 1, paste, collapse='|'), file=tpath, sep='\n', append=T)
} else {
cat("|Table 1|Table 2|Join by field Table 1|Join by field Table 2|\n", file=tpath)
cat("|------------------|-------------------|--------------------|---------------------|\n",
file=tpath, append=T)
cat(apply(tjt, 1, paste, collapse='|'), file=tpath, sep='\n', append=T)
}
tlengths <- rbind(tlengths, c(dpid, nrow(tjt)))
}
tlengths <- character()
for(i in 1:length(dps)) {
# pull out all the table joining tables
tpath <- paste(dps[i], "Table.joining.md", sep="/")
tmd <- try(suppressWarnings(readLines(tpath)), silent=TRUE)
if(class(tmd)=="try-error") {
next
}
if(length(tmd)==0) {
next
}
if(identical(tmd, "")) {
next
}
# download data to get table names
dpid <- regmatches(dps[i], regexpr('DP[0-4]{1}[.][0-9]{5}[.]00[0-2]', dps[i]))
dat <- loadByProduct(dpid, site=c('HARV', 'ARIK', 'NIWO', 'SUGG'),
startdate='2019-10', enddate='2019-12',
package='expanded',
check.size=F, token=Sys.getenv('NEON_TOKEN'))
# subset to just data tables
dat.tab <- grep('variables|validation|categorical|readme|issue', names(dat), invert=T, value=T)
# if only one data table, print and move on
if(length(dat.tab)==1) {
print(dat.tab)
next
}
# get table types from neonUtilities
ttypes <- table_types[which(table_types$tableName %in% dat.tab), c('tableName', 'tableType')]
# pull QSG data out of markdown
l <- lapply(tmd, FUN=function(x) {
y <- unlist(strsplit(x, "|", fixed=TRUE))
y <- gsub("\\", y, replacement="", fixed=TRUE)
return(y)
})
# convert data to table form
tab <- do.call(rbind.data.frame, l)
tab <- tab[-c(1,2),-1]
if(ncol(tab)==3) {
tab$JoinByTable2 <- tab[,3]
}
names(tab) <- c("Table1","Table2","JoinByTable1","JoinByTable2")
# if a table is in the QSG but not in download, print warning
if(!all(union(tab$Table1, tab$Table2) %in% dat.tab)) {
mis <- setdiff(union(tab$Table1, tab$Table2), dat.tab)
print(paste('Tables ', paste(mis, sep=', '), ' not found in downloaded data.', sep=''))
}
# check for site-all, lab-all, and lab-current tables
if(length(which(ttypes$tableType %in% c('site-all','lab-all','lab-current')))>0) {
nomerge <- dat.tab[which(dat.tab %in%
ttypes$tableName[which(ttypes$tableType %in%
c('site-all',
'lab-all',
'lab-current'))])]
dat.tab <- dat.tab[!dat.tab %in% nomerge]
} else {
nomerge <- NA
}
# combinations of tables
dat.c <- data.frame(t(combn(dat.tab, 2)))
# is each combination in the QSG?
ind <- numeric()
for(j in 1:nrow(dat.c)) {
if(paste(dat.c[j,], collapse='.') %in% paste(tab$Table1, tab$Table2, sep='.') |
paste(dat.c[j,], collapse='.') %in% paste(tab$Table2, tab$Table1, sep='.')) {
ind <- c(ind, j)
}
}
# remove pairs accounted for
dat.sub <- dat.c[-ind,]
names(dat.sub) <- c('Table1', 'Table2')
# append to table
tjt <- data.table::rbindlist(list(tab, dat.sub), fill=T)
# check need for 4 columns
if(identical(tjt$JoinByTable1,tjt$JoinByTable2)) {
tjt <- tjt[,c('Table1', 'Table2', 'JoinByTable1')]
}
# append lab and site-all tables
if(!is.na(nomerge)) {
notrec <- data.frame(cbind(nomerge,
'Join not recommended. Data resolution does not match other tables.'))
names(notrec) <- c('Table1', 'JoinByTable1')
tjt <- data.table::rbindlist(list(tjt, notrec), fill=T)
}
# write back to markdown
if(ncol(tjt)==3) {
cat("|Table 1|Table 2|Join by field(s)|\n", file=tpath)
cat("|------------------------|------------------------|-------------------------------|\n",
file=tpath, append=T)
cat(apply(tjt, 1, paste, collapse='|'), file=tpath, sep='\n', append=T)
} else {
cat("|Table 1|Table 2|Join by field Table 1|Join by field Table 2|\n", file=tpath)
cat("|------------------|-------------------|--------------------|---------------------|\n",
file=tpath, append=T)
cat(apply(tjt, 1, paste, collapse='|'), file=tpath, sep='\n', append=T)
}
tlengths <- rbind(tlengths, c(dpid, nrow(tjt)))
}
tlengths <- character()
for(i in 1:length(dps)) {
# pull out all the table joining tables
tpath <- paste(dps[i], "Table.joining.md", sep="/")
tmd <- try(suppressWarnings(readLines(tpath)), silent=TRUE)
if(class(tmd)=="try-error") {
next
}
if(length(tmd)==0) {
next
}
if(identical(tmd, "")) {
next
}
# download data to get table names
dpid <- regmatches(dps[i], regexpr('DP[0-4]{1}[.][0-9]{5}[.]00[0-2]', dps[i]))
dat <- loadByProduct(dpid, site=c('HARV', 'ARIK', 'NIWO', 'SUGG'),
startdate='2019-01', enddate='2019-12',
package='expanded',
check.size=F, token=Sys.getenv('NEON_TOKEN'))
# subset to just data tables
dat.tab <- grep('variables|validation|categorical|readme|issue', names(dat), invert=T, value=T)
# if only one data table, print and move on
if(length(dat.tab)==1) {
print(dat.tab)
next
}
# get table types from neonUtilities
ttypes <- table_types[which(table_types$tableName %in% dat.tab), c('tableName', 'tableType')]
# pull QSG data out of markdown
l <- lapply(tmd, FUN=function(x) {
y <- unlist(strsplit(x, "|", fixed=TRUE))
y <- gsub("\\", y, replacement="", fixed=TRUE)
return(y)
})
# convert data to table form
tab <- do.call(rbind.data.frame, l)
tab <- tab[-c(1,2),-1]
if(ncol(tab)==3) {
tab$JoinByTable2 <- tab[,3]
}
names(tab) <- c("Table1","Table2","JoinByTable1","JoinByTable2")
# if a table is in the QSG but not in download, print warning
if(!all(union(tab$Table1, tab$Table2) %in% dat.tab)) {
mis <- setdiff(union(tab$Table1, tab$Table2), dat.tab)
print(paste('Tables ', paste(mis, sep=', '), ' not found in downloaded data.', sep=''))
}
# check for site-all, lab-all, and lab-current tables
if(length(which(ttypes$tableType %in% c('site-all','lab-all','lab-current')))>0) {
nomerge <- dat.tab[which(dat.tab %in%
ttypes$tableName[which(ttypes$tableType %in%
c('site-all',
'lab-all',
'lab-current'))])]
dat.tab <- dat.tab[!dat.tab %in% nomerge]
} else {
nomerge <- NA
}
# combinations of tables
dat.c <- data.frame(t(combn(dat.tab, 2)))
# is each combination in the QSG?
ind <- numeric()
for(j in 1:nrow(dat.c)) {
if(paste(dat.c[j,], collapse='.') %in% paste(tab$Table1, tab$Table2, sep='.') |
paste(dat.c[j,], collapse='.') %in% paste(tab$Table2, tab$Table1, sep='.')) {
ind <- c(ind, j)
}
}
# remove pairs accounted for
dat.sub <- dat.c[-ind,]
names(dat.sub) <- c('Table1', 'Table2')
# append to table
tjt <- data.table::rbindlist(list(tab, dat.sub), fill=T)
# check need for 4 columns
if(identical(tjt$JoinByTable1,tjt$JoinByTable2)) {
tjt <- tjt[,c('Table1', 'Table2', 'JoinByTable1')]
}
# append lab and site-all tables
if(!is.na(nomerge)) {
notrec <- data.frame(cbind(nomerge,
'Join not recommended. Data resolution does not match other tables.'))
names(notrec) <- c('Table1', 'JoinByTable1')
tjt <- data.table::rbindlist(list(tjt, notrec), fill=T)
}
# write back to markdown
if(ncol(tjt)==3) {
cat("|Table 1|Table 2|Join by field(s)|\n", file=tpath)
cat("|------------------------|------------------------|-------------------------------|\n",
file=tpath, append=T)
cat(apply(tjt, 1, paste, collapse='|'), file=tpath, sep='\n', append=T)
} else {
cat("|Table 1|Table 2|Join by field Table 1|Join by field Table 2|\n", file=tpath)
cat("|------------------|-------------------|--------------------|---------------------|\n",
file=tpath, append=T)
cat(apply(tjt, 1, paste, collapse='|'), file=tpath, sep='\n', append=T)
}
tlengths <- rbind(tlengths, c(dpid, nrow(tjt)))
}
dps[3]
i
dps[28]
tlengths <- character()
for(i in 1:length(dps)) {
# pull out all the table joining tables
tpath <- paste(dps[i], "Table.joining.md", sep="/")
tmd <- try(suppressWarnings(readLines(tpath)), silent=TRUE)
if(class(tmd)=="try-error") {
next
}
if(length(tmd)==0) {
next
}
if(identical(tmd, "")) {
next
}
# download data to get table names
dpid <- regmatches(dps[i], regexpr('DP[0-4]{1}[.][0-9]{5}[.]00[0-2]', dps[i]))
dat <- loadByProduct(dpid, site=c('HARV', 'ARIK', 'YELL', 'SUGG'),
startdate='2018-01', enddate='2018-12',
package='expanded',
check.size=F, token=Sys.getenv('NEON_TOKEN'))
# subset to just data tables
dat.tab <- grep('variables|validation|categorical|readme|issue', names(dat), invert=T, value=T)
# if only one data table, print and move on
if(length(dat.tab)==1) {
print(dat.tab)
next
}
# get table types from neonUtilities
ttypes <- table_types[which(table_types$tableName %in% dat.tab), c('tableName', 'tableType')]
# pull QSG data out of markdown
l <- lapply(tmd, FUN=function(x) {
y <- unlist(strsplit(x, "|", fixed=TRUE))
y <- gsub("\\", y, replacement="", fixed=TRUE)
return(y)
})
# convert data to table form
tab <- do.call(rbind.data.frame, l)
tab <- tab[-c(1,2),-1]
if(ncol(tab)==3) {
tab$JoinByTable2 <- tab[,3]
}
names(tab) <- c("Table1","Table2","JoinByTable1","JoinByTable2")
# if a table is in the QSG but not in download, print warning
if(!all(union(tab$Table1, tab$Table2) %in% dat.tab)) {
mis <- setdiff(union(tab$Table1, tab$Table2), dat.tab)
print(paste('Tables ', paste(mis, sep=', '), ' not found in downloaded data.', sep=''))
}
# check for site-all, lab-all, and lab-current tables
if(length(which(ttypes$tableType %in% c('site-all','lab-all','lab-current')))>0) {
nomerge <- dat.tab[which(dat.tab %in%
ttypes$tableName[which(ttypes$tableType %in%
c('site-all',
'lab-all',
'lab-current'))])]
dat.tab <- dat.tab[!dat.tab %in% nomerge]
} else {
nomerge <- NA
}
# combinations of tables
dat.c <- data.frame(t(combn(dat.tab, 2)))
# is each combination in the QSG?
ind <- numeric()
for(j in 1:nrow(dat.c)) {
if(paste(dat.c[j,], collapse='.') %in% paste(tab$Table1, tab$Table2, sep='.') |
paste(dat.c[j,], collapse='.') %in% paste(tab$Table2, tab$Table1, sep='.')) {
ind <- c(ind, j)
}
}
# remove pairs accounted for
dat.sub <- dat.c[-ind,]
names(dat.sub) <- c('Table1', 'Table2')
# append to table
tjt <- data.table::rbindlist(list(tab, dat.sub), fill=T)
# check need for 4 columns
if(identical(tjt$JoinByTable1,tjt$JoinByTable2)) {
tjt <- tjt[,c('Table1', 'Table2', 'JoinByTable1')]
}
# append lab and site-all tables
if(!is.na(nomerge)) {
notrec <- data.frame(cbind(nomerge,
'Join not recommended. Data resolution does not match other tables.'))
names(notrec) <- c('Table1', 'JoinByTable1')
tjt <- data.table::rbindlist(list(tjt, notrec), fill=T)
}
# write back to markdown
if(ncol(tjt)==3) {
cat("|Table 1|Table 2|Join by field(s)|\n", file=tpath)
cat("|------------------------|------------------------|-------------------------------|\n",
file=tpath, append=T)
cat(apply(tjt, 1, paste, collapse='|'), file=tpath, sep='\n', append=T)
} else {
cat("|Table 1|Table 2|Join by field Table 1|Join by field Table 2|\n", file=tpath)
cat("|------------------|-------------------|--------------------|---------------------|\n",
file=tpath, append=T)
cat(apply(tjt, 1, paste, collapse='|'), file=tpath, sep='\n', append=T)
}
tlengths <- rbind(tlengths, c(dpid, nrow(tjt)))
}
identical(nomerge, NA)
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://api.track.toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-11-20', until='2020-11-20'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(devtools)
library(neonUtilities)
setwd("~/GitHub/NEON-OS-data-processing/neonOS")
library(neonOS)
# mammals
mam <- loadByProduct(dpID='DP1.10072.001', site='JERC', startdate='2016-01', enddate='2017-12',
package='expanded', check.size=F, token=Sys.getenv('NEON_TOKEN'))
mam.dup.plot <- removeDups(mam$mam_perplotnight, variables=mam$variables_10072, table='mam_perplotnight')
data <- mam$mam_perplotnight
variables <- mam$variables_10072
table <- 'mam_perplotnight'
if(length(which(variables$downloadPkg=="none"))>0) {
variables <- variables[which(variables$downloadPkg!="none"),]
}
varnames <- variables$fieldName[which(variables$table==table)]
if(!all(names(data) %in% varnames) |
!all(varnames %in% names(data))) {
dif <- setdiff(varnames, names(data))
if(length(dif)!=0) {
if(all(dif %in% variables$fieldName[which(variables$downloadPkg=="expanded" &
variables$table==table)])) {
stop("Input data appear to be the basic download package. The expanded data package is required for removeDups() to identify all duplicates correctly.")
}
}
stop(paste("Field names in data do not match variables file.\n",
paste0(setdiff(names(data), varnames), collapse=" "),
ifelse(length(setdiff(names(data), varnames))>0,
" are in data and not in variables file;\n",
""),
paste0(setdiff(varnames, names(data)), collapse=" "),
ifelse(length(setdiff(varnames, names(data)))>0,
" are in variables file and not in data.",
""), sep=""))
}
key <- as.character(variables$fieldName[which(variables$table==table & variables$primaryKey=="Y")])
if(length(key)==0) {
stop("No primary key identified in variables file.")
}
if(length(unique(data$uid)) != length(data$uid)) {
# check if entire records are duplicates
if(length(which(duplicated(data)))==length(which(duplicated(data$uid)))) {
data <- data[-which(duplicated(data$uid)),]
cat("Data contain identical records with identical uid. This indicates data have been combined from multiple downloads. Duplicate records have been removed without flagging.\n")
} else {
stop("Data contain records with identical uid but differing data values. This indicates something has gone wrong with the data post-download.\nStart over with a fresh download of the current data.")
}
}
# Initiate duplicateRecordQF field at 0
data$duplicateRecordQF <- 0
if(length(key)>1) {
data[,which(names(data) %in% key)] <- lapply(data[,which(names(data) %in% key)],
function (x) as.character(x))
} else {
data[,which(names(data) %in% key)] <- as.character(data[,which(names(data) %in% key)])
}
# make key value field
if(length(key)==1) {
data$keyvalue <- tolower(data[,key])
} else {
data$keyvalue <- tolower(do.call(paste0, data[key]))
}
# make identifier that isn't uid (since uids of duplicates will be concatenated)
data$rowid <- 1:nrow(data)
data.low <- apply(data, 2, tolower)
data.low <- data.frame(data.low, stringsAsFactors=F)
# convert any empty strings to NAs
data.low[data.low==""] <- NA
nrow(unique(cbind(data.low[,key])))==nrow(data.low)
# subset to only the records with duplicate values in the key fields
data.sub <- data.low[union(which(duplicated(data.low[,key])),
which(duplicated(data.low[,key], fromLast=T))),]
dup.keys <- cbind(unique(data.sub[,key]))
cat(nrow(dup.keys), "duplicated key values found, representing",
nrow(data.sub), "non-unique records. Attempting to resolve.\n")
pb <- utils::txtProgressBar(style=3)
utils::setTxtProgressBar(pb, 1/nrow(dup.keys))
ct <- 0
nrow(dup.keys)
i <- 1
if(ncol(dup.keys)==1) {
na.check <- dup.keys[i]
dup.keyvalue <- dup.keys[i]
} else {
na.check <- dup.keys[i,]
dup.keyvalue <- paste0(dup.keys[i,])
}
if(all(is.na(na.check))) {
data$duplicateRecordQF[which(data$keyvalue %in% dup.keyvalue)] <- -1
next
}
unique(data$duplicateRecordQF)
# flag remaining, unresolved duplicates
# if some in a group are resolved and some aren't, all end up with QF=2
unres.dups <- union(which(duplicated(data$keyvalue)),
which(duplicated(data$keyvalue, fromLast=T)))
unres.dups
any(data$dupduplicateRecordQF==-1)
which(data$duplicateRecordQF==-1)
any(data$duplicateRecordQF==-1)
unres.dups <- setdiff(unres.dups, which(data$duplicateRecordQF==-1))
data$duplicateRecordQF[unres.dups] <- 2
unique(data$duplicateRecordQF)
check()
install('.')
