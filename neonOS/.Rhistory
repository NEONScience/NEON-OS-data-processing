# path to directory to read and write data
# ------------------------
pathToFiles <- '/Users/clunch/Desktop/eyeball_demo/NEON_n-inorg-soil/stackedFiles/'
# ------------------------
# name of file to display, located in read/write directory set above.
# ------------------------
fileName <- 'ntr_externalLab.csv'
pathToFile <- paste(pathToFiles, fileName, sep='/')
pathToFile
# ------------------------
# path to directory to read and write data
# ------------------------
pathToFiles <- '/Users/clunch/Desktop/eyeball_demo/NEON_n-inorg-soil/stackedFiles'
# ------------------------
# name of file to display, located in read/write directory set above.
# ------------------------
fileName <- 'ntr_externalLab.csv'
pathToFile <- paste(pathToFiles, fileName, sep='/')
pathToFile
filesInput <- pathToFile
wb <- read.delim(wbInput, header=T, sep='\t', stringsAsFactors=F)
wbInput <- wbPath
wb <- read.delim(wbInput, header=T, sep='\t', stringsAsFactors=F)
wb$table <- gsub('_pub', '', wb$table)
wb$table <- gsub('_in', '', wb$table)
allFiles <- read.delim(filesInput, header=T, sep=',', stringsAsFactors=F)
allFiles <- list(allFiles)
names(allFiles) <- gsub('.csv', '', filesInput)
length(allFiles)
names(allFiles)
250/30
250/60
req <- GET("https://toggl.com/reports/api/v2/details",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
noon <- paste(Sys.Date(), "T12:00:00-07:00", sep="")
pre <- parsed$data[which(parsed$data$end<noon),c("dur","project")]
post <- parsed$data[which(parsed$data$start>=noon),c("dur","project")]
pre$dur <- round(pre$dur/(60*60*1000), 1)
post$dur <- round(post$dur/(60*60*1000), 1)
if(nrow(parsed$data[which(parsed$data$end>noon & parsed$data$start<noon),])>0) {
crossNoon <- parsed$data[which(parsed$data$end>noon & parsed$data$start<noon),]
crossPre <- round(difftime(as.POSIXct(noon, format="%Y-%m-%dT%H:%M:%S"),
as.POSIXct(crossNoon$start, format="%Y-%m-%dT%H:%M:%S"), units="hours"), 1)
crossPost <- round(difftime(as.POSIXct(crossNoon$end, format="%Y-%m-%dT%H:%M:%S"),
as.POSIXct(noon, format="%Y-%m-%dT%H:%M:%S"), units="hours"), 1)
pre <- rbind(pre, c(as.character(crossPre), crossNoon$project))
post <- rbind(post, c(as.character(crossPost), crossNoon$project))
colnames(pre) <- c("dur","project")
colnames(post) <- c("dur","project")
pre$dur <- as.numeric(as.character(pre$dur))
post$dur <- as.numeric(as.character(post$dur))
}
preNoon <- aggregate(pre$dur, by=list(pre$project), FUN=sum)
postNoon <- aggregate(post$dur, by=list(post$project), FUN=sum)
preNoon
postNoon
library(jsonlite)
library(httr)
req <- GET("https://toggl.com/reports/api/v2/details",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
noon <- paste(Sys.Date(), "T12:00:00-07:00", sep="")
pre <- parsed$data[which(parsed$data$end<noon),c("dur","project")]
post <- parsed$data[which(parsed$data$start>=noon),c("dur","project")]
pre$dur <- round(pre$dur/(60*60*1000), 1)
post$dur <- round(post$dur/(60*60*1000), 1)
if(nrow(parsed$data[which(parsed$data$end>noon & parsed$data$start<noon),])>0) {
crossNoon <- parsed$data[which(parsed$data$end>noon & parsed$data$start<noon),]
crossPre <- round(difftime(as.POSIXct(noon, format="%Y-%m-%dT%H:%M:%S"),
as.POSIXct(crossNoon$start, format="%Y-%m-%dT%H:%M:%S"), units="hours"), 1)
crossPost <- round(difftime(as.POSIXct(crossNoon$end, format="%Y-%m-%dT%H:%M:%S"),
as.POSIXct(noon, format="%Y-%m-%dT%H:%M:%S"), units="hours"), 1)
pre <- rbind(pre, c(as.character(crossPre), crossNoon$project))
post <- rbind(post, c(as.character(crossPost), crossNoon$project))
colnames(pre) <- c("dur","project")
colnames(post) <- c("dur","project")
pre$dur <- as.numeric(as.character(pre$dur))
post$dur <- as.numeric(as.character(post$dur))
}
preNoon <- aggregate(pre$dur, by=list(pre$project), FUN=sum)
postNoon <- aggregate(post$dur, by=list(post$project), FUN=sum)
preNoon
postNoon
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/details",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
noon <- paste(Sys.Date(), "T12:00:00-07:00", sep="")
pre <- parsed$data[which(parsed$data$end<noon),c("dur","project")]
post <- parsed$data[which(parsed$data$start>=noon),c("dur","project")]
pre$dur <- round(pre$dur/(60*60*1000), 1)
post$dur <- round(post$dur/(60*60*1000), 1)
if(nrow(parsed$data[which(parsed$data$end>noon & parsed$data$start<noon),])>0) {
crossNoon <- parsed$data[which(parsed$data$end>noon & parsed$data$start<noon),]
crossPre <- round(difftime(as.POSIXct(noon, format="%Y-%m-%dT%H:%M:%S"),
as.POSIXct(crossNoon$start, format="%Y-%m-%dT%H:%M:%S"), units="hours"), 1)
crossPost <- round(difftime(as.POSIXct(crossNoon$end, format="%Y-%m-%dT%H:%M:%S"),
as.POSIXct(noon, format="%Y-%m-%dT%H:%M:%S"), units="hours"), 1)
pre <- rbind(pre, c(as.character(crossPre), crossNoon$project))
post <- rbind(post, c(as.character(crossPost), crossNoon$project))
colnames(pre) <- c("dur","project")
colnames(post) <- c("dur","project")
pre$dur <- as.numeric(as.character(pre$dur))
post$dur <- as.numeric(as.character(post$dur))
}
preNoon <- aggregate(pre$dur, by=list(pre$project), FUN=sum)
postNoon <- aggregate(post$dur, by=list(post$project), FUN=sum)
preNoon
postNoon
shiny::runApp('GitHub/NateFork/eyeball-checker-shiny-app/app')
runApp('GitHub/NateFork/eyeball-checker-shiny-app/app')
runApp('GitHub/NateFork/eyeball-checker-shiny-app/app')
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
#           query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-17', until='2020-03-17'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
#           query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
80-67.8
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(restR)
pars <- get.parser()
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/details",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
noon <- paste(Sys.Date(), "T12:00:00-07:00", sep="")
pre <- parsed$data[which(parsed$data$end<noon),c("dur","project")]
post <- parsed$data[which(parsed$data$start>=noon),c("dur","project")]
pre$dur <- round(pre$dur/(60*60*1000), 1)
post$dur <- round(post$dur/(60*60*1000), 1)
if(nrow(parsed$data[which(parsed$data$end>noon & parsed$data$start<noon),])>0) {
crossNoon <- parsed$data[which(parsed$data$end>noon & parsed$data$start<noon),]
crossPre <- round(difftime(as.POSIXct(noon, format="%Y-%m-%dT%H:%M:%S"),
as.POSIXct(crossNoon$start, format="%Y-%m-%dT%H:%M:%S"), units="hours"), 1)
crossPost <- round(difftime(as.POSIXct(crossNoon$end, format="%Y-%m-%dT%H:%M:%S"),
as.POSIXct(noon, format="%Y-%m-%dT%H:%M:%S"), units="hours"), 1)
pre <- rbind(pre, c(as.character(crossPre), crossNoon$project))
post <- rbind(post, c(as.character(crossPost), crossNoon$project))
colnames(pre) <- c("dur","project")
colnames(post) <- c("dur","project")
pre$dur <- as.numeric(as.character(pre$dur))
post$dur <- as.numeric(as.character(post$dur))
}
preNoon <- aggregate(pre$dur, by=list(pre$project), FUN=sum)
postNoon <- aggregate(post$dur, by=list(post$project), FUN=sum)
preNoon
postNoon
utilitiesD <- cranlogs::cran_downloads("neonUtilities", from="2019-12-01", to="2020-04-13")
View(utilitiesD)
utilitiesD <- cranlogs::cran_downloads("neonUtilities", from="2020-03-01", to="2020-04-13")
sum(utilitiesD$count[1:31])
sum(utilitiesD$count[1:7])
sum(utilitiesD$count[8:15])
sum(utilitiesD$count[16:22])
sum(utilitiesD$count[23:29])
sum(utilitiesD$count[30:36])
sum(utilitiesD$count[37:43])
ltr <- read.delim('/Users/clunch/Downloads/L1_Results_Litter_chemical_properties/L1_Results_ltr_litterCarbonNitrogen_pub.txt', sep='\t')
unique(ltr$siteID)
library(neonUtilities)
ltr.portal <- stackByTable('/Users/clunch/Downloads/NEON_chem-litter.zip', savepath = 'envt')
unique(ltr.portal$ltr_litterCarbonNitrogen$siteID)
unique(ltr.portal$ltr_litterLignin$siteID)
sort(union(unique(ltr.portal$ltr_litterCarbonNitrogen$siteID), unique(ltr.portal$ltr_litterLignin$siteID)))
levels(ltr$siteID)
ltr.lig <- read.delim('/Users/clunch/Downloads/L1_Results_Litter_chemical_properties/L1_Results_ltr_litterLignin_pub.txt', sep='\t')
levels(ltr.lig$siteID)
sort(union(levels(ltr$siteID), levels(ltr.lig$siteID)))
m <- lubridate::month(ltr.lig$End.Date)
unique(cbind(m, ltr.lig$siteID))
unique(cbind(m, as.character(ltr.lig$siteID)))
sort(unique(cbind(as.character(ltr.lig$siteID), m)))
site <- 'SCBI'
req <- httr::GET(paste('http://data.neonscience.org/api/v0/locations/', site, sep=''))
req.content <- httr::content(req, as='parsed')
loc <- loc$data$locationChildrenUrls[which(substring(loc$data$locationChildren, 1, 4)!=site)]
loc <- jsonlite::fromJSON(httr::content(req, as='text', encoding='UTF-8'))
loc <- loc$data$locationChildrenUrls[which(substring(loc$data$locationChildren, 1, 4)!=site)]
loc.des <- unlist(lapply(loc, getLocChildren))
source('~/GitHub/NEON-geolocation/geoNEON/R/getLocChildren.R')
loc.des <- unlist(lapply(loc, getLocChildren))
loc <- loc$data$locationChildren[which(substring(loc$data$locationChildren, 1, 4)!=site)]
loc <- jsonlite::fromJSON(httr::content(req, as='text', encoding='UTF-8'))
loc <- loc$data$locationChildren[which(substring(loc$data$locationChildren, 1, 4)!=site)]
loc.des <- unlist(lapply(loc, getLocChildren))
getLocChildren('POSE')
loc <- jsonlite::fromJSON(httr::content(req, as='text', encoding='UTF-8'))
loc$data$locationType
loc$data$locationDescription
loc$data$locationProperties$locationPropertyName
getLocValues(loc)
source('~/GitHub/NEON-geolocation/geoNEON/R/getLocValues.R')
getLocValues(loc)
length(loc$data$locationChildren)
618*9
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
veg <- read.delim('/Users/clunch/Desktop/apparentindividuals_dups.csv', sep=',', stringsAsFactors = F)
veg.dup <- veg[which(veg$duplicateRecordQF==2),]
plyr::count(veg.dup, 'growthForm')
180*5
900/60
library(devtools)
install_github('NateMietk/NEON-utilities/neonUtilities', ref='master')
options(stringsAsFactors = F)
m <- read.delim('https://www.neonscience.org/science-design/field-sites/export', sep=',')
mat <- data.frame(matrix(unlist(strsplit(m$Mean.Annual.Temperature, '/', fixed=T)), ncol=2, byrow=T))
mat[,1] <- gsub('C', '', mat[,1])
mat <- mat[,1]
mat <- as.numeric(mat)
map <- gsub(' mm', '', m$Mean.Annual.Precipitation)
map <- as.numeric(map)
View(m)
mm <- cbind(m$Site.ID, mat, map)
mm <- data.frame(mm)
names(mm) <- c('site','mat','map')
View(mm)
library(neonUtilities)
scc <- loadByProduct(dpID='DP1.10008.001', package='expanded', check.size=F)
sch <- scc$spc_biogeochem
View(sch)
names(mm) <- c('siteID','mat','map')
sch <- merge(sch, mm, by='siteID', all.x=T)
plot(sch$carbonTot~sch$mat, pch=20)
plot(sch$carbonTot~sch$map, pch=20)
plot(sch$nitrogenTot~sch$mat, pch=20)
plot(sch$nitrogenTot~sch$map, pch=20)
View(sch)
plot(sch$carbonTot[grep('O', sch$horizonName, invert=T)]~sch$mat[grep('O', sch$horizonName, invert=T)], pch=20)
plot(sch$carbonTot[grep('O', sch$horizonName, invert=T)]~sch$map[grep('O', sch$horizonName, invert=T)], pch=20)
sc <- aggregate(cbind(sch$carbonTot, sch$mat, sch$map),
by=list(sch$siteID, sch$horizonName), FUN=mean, na.rm=T)
head(sc)
sch$carbonTot <- as.numeric(sch$carbonTot)
sch$mat <- as.numeric(sch$mat)
sch$map <- as.numeric(sch$map)
sc <- aggregate(cbind(sch$carbonTot, sch$mat, sch$map),
by=list(sch$siteID, sch$horizonName), FUN=mean, na.rm=T)
head(sc)
names(sc) <- c('site','horizon','carbonTot','mat','map')
plot(sc$carbonTot~sc$mat, pch=20)
plot(sc$carbonTot~sc$map, pch=20)
sp <- aggregate(cbind(sch$carbonTot, sch$mat, sch$map),
by=list(sch$siteID, sch$plotID), FUN=mean, na.rm=T)
names(sp) <- c('site','plot','carbonTot','mat','map')
head(sp)
plot(sp$carbonTot~sc$mat, pch=20)
plot(sp$carbonTot~sp$mat, pch=20)
plot(sp$carbonTot~sp$map, pch=20)
par(mfrow=c(1,2))
plot(sch$carbonTot~sch$mat, pch=20,
xlab='Mean annual temperature',
ylab='Total soil carbon', tck=0.01)
plot(sch$carbonTot~sch$map, pch=20,
xlab='Mean annual precipitation',
ylab='Total soil carbon', tck=0.01)
library(geoNEON)
loc.os <- getLocBySite('ARIK', type='OS')
View(loc.os)
loc <- getLocBySite('ARIK', type='all')
View(loc)
View(loc)
View(loc)
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
80-76.7
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
install.packages(neonUtilities)
install.packages('neonUtilities')
library(devtools)
library(neonUtilities)
fs <- loadByProduct(dpID='DP1.30012.001', check.size=F)
names(fs)
View(fs$fsp_sampleMetadata)
# should display message about avg= and download all data
waq <- loadByProduct(dpID='DP1.20288.001', site=c('ARIK','MCRA'),
avg=5, check.size=F)
wch <- loadByProduct(dpID='DP1.20093.001', site=c('ARIK','POSE'),
package='expanded', check.size=F)
View(wch$swc_externalLabDataByAnalyte)
gwch <- loadByProduct(dpID='DP1.20092.001', site=c('ARIK','POSE'),
package='expanded', check.size=F)
View(gwch$categoricalCodes_20092)
nchar('NEON data can be downloaded from either the NEON Data Portal or . ')
nchar('NEON data can be downloaded from either the NEON Data Portal or the NEON API. ')
nchar('If you've never downloaded NEON data via the neonUtilities package before, ')
nchar('an API token can link your downloads to your account, as well as enabling faster ')
nchar('reach of the observatory, and to advocate for training activities, workshops, ')
nchar('and how many users in total are downloading data. This information helps NEON ')
nchar('Your API token is unique to your account, so don't share it! If you're ')
nchar('Your API token is unique to your account, so don't share it! If you"re ')
nchar('Your API token is unique to your account, so don"t share it! If you"re ')
nchar('accessible to your code. But first let"s try out using the token the easy ')
nchar('If you"re writing code that will be available publicly, such as in a GitHub ')
Sys.getenv("R_USER")
Sys.getenv("HOME")
nchar('Option 2: Add the token to a `.Renviron` file. This is harder to set up initially,')
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(devtools)
library(neonUtilities)
byTileAOP(dpID = "DP3.30015.001", site = "WREF", year = "2017",
easting = c(571000,743000,578000),
northing = c(5079000,3984000,5080000),
savepath='/Users/clunch/Desktop', check.size = FALSE,
token=Sys.getenv('NEON_TOKEN'))
Sys.getenv('NEON_TOKEN')
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2020-03-16', until='2020-03-16'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(devtools)
library(neonUtilities)
setwd("~/GitHub/NEON-OS-data-processing/neonOS")
library(neonOS)
cfc <- loadByProduct(dpID='DP1.10026.001', check.size=F,
startdate='2017-05', enddate='2019-08',
package='expanded', token=Sys.getenv('NEON_TOKEN'))
cfc.cn <- removeDups(cfc$cfc_elements, variables=cfc$variables_10026, table='cfc_elements')
cfc.cn <- removeDups(cfc$cfc_chlorophyll, variables=cfc$variables_10026, table='cfc_chlorophyll')
bird <- loadByProduct(dpID='DP1.10003.001', check.size=F,
startdate='2017-05', enddate='2019-08',
package='expanded', token=Sys.getenv('NEON_TOKEN'))
brd.d <- removeDups(bird$brd_countdata, variables=bird$variables_10003, table='brd_countdata')
fish <- loadByProduct(dpID='DP1.20107.001', check.size=F,
startdate='2017-05', enddate='2019-08',
package='expanded', token=Sys.getenv('NEON_TOKEN'))
fish.d <- removeDups(fish$fsh_fieldData, variables=fish$variables_20107, table='fsh_fieldData')
fish.p <- removeDups(fish$fsh_perPass, variables=fish$variables_20107, table='fsh_perPass')
cfc <- loadByProduct(dpID='DP1.10026.001', check.size=F,
startdate='2017-05', enddate='2019-08',
token=Sys.getenv('NEON_TOKEN'))
cfc.cn <- removeDups(cfc$cfc_chlorophyll, variables=cfc$variables_10026, table='cfc_chlorophyll')
View(cfc$variables_10026)
install('.')
check()
