tut.title <- grep('title[:]', tut, value=T)
tut.title <- gsub('title: ', '', tut.title)
tut.title <- regmatches(tut.title, regexpr('[a-z &]+', tut.title, ignore.case=T))
tut.dps <- grep('dataProduct', tut, value=T)
if(length(tut.dps)==0) {
tut.dps <- NA
} else {
tut.dps <- gsub('dataProducts', '', tut.dps)
tut.dps <- gsub('dataProduct', '', tut.dps)
tut.dps <- regmatches(tut.dps, regexpr('[a-z0-9 .,;&]+', tut.dps, ignore.case=T))
}
if(length(tut.dps)==0) {
tut.dps <- NA
}
tutorial.dps <- rbind(tutorial.dps, c(tut.title, tut.dps))
}
tutorial.dps <- data.frame(tutorial.dps)
names(tutorial.dps) <- c('Tutorial name','Data products')
View(tutorial.dps)
dps <- character()
for(i in 1:length(fls)) {
tut <- readLines(fls[i])
tut.dps <- grep('dataProduct', tut, value=T)
if(length(tut.dps)==0) {
next
} else {
tut.dps <- gsub('dataProducts', '', tut.dps)
tut.dps <- gsub('dataProduct', '', tut.dps)
tut.dps <- regmatches(tut.dps, regexpr('[a-z0-9 .,;&]+', tut.dps, ignore.case=T))
}
if(length(tut.dps)==0) {
tut.dps <- NA
}
dps <- c(dps, tut.dps)
}
dps <- character()
for(i in 1:length(fls)) {
tut <- readLines(fls[i])
tut.dps <- grep('dataProduct', tut, value=T)
if(length(tut.dps)==0) {
next
} else {
tut.dps <- gsub('dataProducts', '', tut.dps)
tut.dps <- gsub('dataProduct', '', tut.dps)
tut.dps <- regmatches(tut.dps, regexpr('[a-z0-9 .,;&]+', tut.dps, ignore.case=T))
tut.dps <- strsplit(tut.dps, split=',', fixed=T)
tut.dps <- gsub(' ', '', tut.dps)
}
if(length(tut.dps)==0) {
next
}
dps <- c(dps, tut.dps)
}
dps <- character()
for(i in 1:length(fls)) {
tut <- readLines(fls[i])
tut.dps <- grep('dataProduct', tut, value=T)
if(length(tut.dps)==0) {
next
} else {
tut.dps <- gsub('dataProducts', '', tut.dps)
tut.dps <- gsub('dataProduct', '', tut.dps)
tut.dps <- regmatches(tut.dps, regexpr('[a-z0-9 .,;&]+', tut.dps, ignore.case=T))
tut.dps <- unlist(strsplit(tut.dps, split=',', fixed=T))
tut.dps <- gsub(' ', '', tut.dps)
}
if(length(tut.dps)==0) {
next
}
dps <- c(dps, tut.dps)
}
unique(dps)
dps <- character()
tops <- character()
lang <- character()
for(i in 1:length(fls)) {
# read in tutorial
tut <- readLines(fls[i])
# get data products
tut.dps <- grep('dataProduct', tut, value=T)
if(length(tut.dps)==0) {
dps <- dps
} else {
tut.dps <- gsub('dataProducts', '', tut.dps)
tut.dps <- gsub('dataProduct', '', tut.dps)
tut.dps <- regmatches(tut.dps, regexpr('[a-z0-9 .,;&]+', tut.dps, ignore.case=T))
tut.dps <- unlist(strsplit(tut.dps, split=',', fixed=T))
tut.dps <- gsub(' ', '', tut.dps)
}
if(length(tut.dps)==0) {
dps <- dps
}
dps <- c(dps, tut.dps)
# get topics
tut.tops <- grep('topics', tut, value=T)
if(length(tut.tops)==0) {
tops <- tops
} else {
tut.tops <- gsub('topics: ', '', tut.tops)
tut.tops <- regmatches(tut.tops, regexpr('[a-z0-9 .,;&]+', tut.tops, ignore.case=T))
tut.tops <- unlist(strsplit(tut.tops, split=',', fixed=T))
tut.tops <- gsub(' ', '', tut.tops)
}
if(length(tut.tops)==0) {
tops <- tops
}
tops <- c(tops, tut.tops)
# get programming languages
tut.l <- grep('languageTool', tut, value=T)
if(length(tut.l)==0) {
lang <- lang
} else {
tut.l <- gsub('languageTool: ', '', tut.l)
tut.l <- regmatches(tut.l, regexpr('[a-z0-9 .,;&]+', tut.l, ignore.case=T))
tut.l <- unlist(strsplit(tut.l, split=',', fixed=T))
tut.l <- gsub(' ', '', tut.l)
}
if(length(tut.l)==0) {
lang <- lang
}
lang <- c(lang, tut.l)
}
unique(dps)
unique(tops)
unique(lang)
dps <- character()
tops <- character()
lang <- character()
for(i in 1:length(fls)) {
# read in tutorial
tut <- readLines(fls[i])
# get data products
tut.dps <- grep('dataProduct', tut, value=T)
if(length(tut.dps)==0) {
dps <- dps
} else {
tut.dps <- gsub('dataProducts', '', tut.dps)
tut.dps <- gsub('dataProduct', '', tut.dps)
tut.dps <- regmatches(tut.dps, regexpr('[a-z0-9 .,;&]+', tut.dps, ignore.case=T))
tut.dps <- unlist(strsplit(tut.dps, split=',', fixed=T))
tut.dps <- gsub(' ', '', tut.dps)
}
if(length(tut.dps)==0) {
dps <- dps
}
dps <- c(dps, tut.dps)
# get topics
tut.tops <- grep('topics', tut, value=T)
if(length(tut.tops)==0) {
tops <- tops
} else {
tut.tops <- gsub('topics: ', '', tut.tops)
tut.tops <- regmatches(tut.tops, regexpr('[a-z0-9 .,;&-]+', tut.tops, ignore.case=T))
tut.tops <- unlist(strsplit(tut.tops, split=',', fixed=T))
tut.tops <- gsub(' ', '', tut.tops)
}
if(length(tut.tops)==0) {
tops <- tops
}
tops <- c(tops, tut.tops)
# get programming languages
tut.l <- grep('languageTool', tut, value=T)
if(length(tut.l)==0) {
lang <- lang
} else {
tut.l <- gsub('languageTool: ', '', tut.l)
tut.l <- regmatches(tut.l, regexpr('[a-z0-9 .,;&]+', tut.l, ignore.case=T))
tut.l <- unlist(strsplit(tut.l, split=',', fixed=T))
tut.l <- gsub(' ', '', tut.l)
}
if(length(tut.l)==0) {
lang <- lang
}
lang <- c(lang, tut.l)
}
unique(dps)
unique(tops)
dps <- character()
tops <- character()
lang <- character()
for(i in 1:length(fls)) {
# read in tutorial
tut <- readLines(fls[i])
# get data products
tut.dps <- grep('dataProduct', tut, value=T)
if(length(tut.dps)==0) {
dps <- dps
} else {
tut.dps <- gsub('dataProducts', '', tut.dps)
tut.dps <- gsub('dataProduct', '', tut.dps)
tut.dps <- regmatches(tut.dps, regexpr('[a-z0-9 .,;&]+', tut.dps, ignore.case=T))
tut.dps <- unlist(strsplit(tut.dps, split=',', fixed=T))
tut.dps <- gsub(' ', '', tut.dps)
}
if(length(tut.dps)==0) {
dps <- dps
}
dps <- c(dps, tut.dps)
# get topics
tut.tops <- grep('topics', tut, value=T)
if(length(tut.tops)==0) {
tops <- tops
} else {
tut.tops <- gsub('topics: ', '', tut.tops)
tut.tops <- regmatches(tut.tops, regexpr('[a-z0-9 .,;&-]+', tut.tops, ignore.case=T))
tut.tops <- unlist(strsplit(tut.tops, split=',', fixed=T))
tut.tops <- gsub(' ', '', tut.tops)
}
if(length(tut.tops)==0) {
tops <- tops
}
tops <- c(tops, tut.tops)
# get programming languages
tut.l <- grep('languageTool', tut, value=T)
if(length(tut.l)==0) {
lang <- lang
} else {
tut.l <- gsub('languageTool: ', '', tut.l)
tut.l <- regmatches(tut.l, regexpr('[a-z0-9 .,;&-]+', tut.l, ignore.case=T))
tut.l <- unlist(strsplit(tut.l, split=',', fixed=T))
tut.l <- gsub(' ', '', tut.l)
}
if(length(tut.l)==0) {
lang <- lang
}
lang <- c(lang, tut.l)
}
unique(dps)
unique(tops)
unique(lang)
writeLines(tops, '/Users/clunch/Desktop/tutorial_topics.txt')
writeLines(unique(tops), '/Users/clunch/Desktop/tutorial_topics.txt')
writeLines(unique(lang), '/Users/clunch/Desktop/tutorial_langs.txt')
dps <- character()
tops <- character()
lang <- character()
for(i in 1:length(fls)) {
# read in tutorial
tut <- readLines(fls[i])
# get data products
tut.dps <- grep('dataProduct', tut, value=T)
if(length(tut.dps)==0) {
dps <- dps
} else {
tut.dps <- gsub('dataProducts', '', tut.dps)
tut.dps <- gsub('dataProduct', '', tut.dps)
tut.dps <- regmatches(tut.dps, regexpr('[a-z0-9 .,;&]+', tut.dps, ignore.case=T))
tut.dps <- unlist(strsplit(tut.dps, split=',', fixed=T))
tut.dps <- gsub(' ', '', tut.dps)
}
if(length(tut.dps)==0) {
dps <- dps
}
dps <- c(dps, tut.dps)
# get topics
tut.tops <- grep('topics', tut, value=T)
if(length(tut.tops)==0) {
tops <- tops
} else {
tut.tops <- gsub('topics: ', '', tut.tops)
tut.tops <- regmatches(tut.tops, regexpr('[a-z0-9 .,;&-]+', tut.tops, ignore.case=T))
tut.tops <- unlist(strsplit(tut.tops, split=',', fixed=T))
tut.tops <- gsub(' ', '', tut.tops)
}
if(length(tut.tops)==0) {
tops <- tops
}
tops <- c(tops, tut.tops)
# get programming languages
tut.l <- grep('languageTool', tut, value=T)
tut.l.2 <- grep('languagesTool', tut, value=T)
tut.l.3 <- grep('languagesTools', tut, value=T)
tut.l.4 <- grep('languageTools', tut, value=T)
tut.l <- c(tut.l, tut.l.2, tut.l.3, tut.l.4)
if(length(tut.l)==0) {
lang <- lang
} else {
tut.l <- gsub('languageTool: ', '', tut.l)
tut.l <- regmatches(tut.l, regexpr('[a-z0-9 .,;&-]+', tut.l, ignore.case=T))
tut.l <- unlist(strsplit(tut.l, split=',', fixed=T))
tut.l <- gsub(' ', '', tut.l)
}
if(length(tut.l)==0) {
lang <- lang
}
lang <- c(lang, tut.l)
}
writeLines(unique(tops), '/Users/clunch/Desktop/tutorial_topics.txt')
writeLines(unique(lang), '/Users/clunch/Desktop/tutorial_langs.txt')
dps <- character()
tops <- character()
lang <- character()
for(i in 1:length(fls)) {
# read in tutorial
tut <- readLines(fls[i])
# get data products
tut.dps <- grep('dataProduct', tut, value=T)
if(length(tut.dps)==0) {
dps <- dps
} else {
tut.dps <- gsub('dataProducts', '', tut.dps)
tut.dps <- gsub('dataProduct', '', tut.dps)
tut.dps <- regmatches(tut.dps, regexpr('[a-z0-9 .,;&]+', tut.dps, ignore.case=T))
tut.dps <- unlist(strsplit(tut.dps, split=',', fixed=T))
tut.dps <- gsub(' ', '', tut.dps)
}
if(length(tut.dps)==0) {
dps <- dps
}
dps <- c(dps, tut.dps)
# get topics
tut.tops <- grep('topics', tut, value=T)
if(length(tut.tops)==0) {
tops <- tops
} else {
tut.tops <- gsub('topics: ', '', tut.tops)
tut.tops <- regmatches(tut.tops, regexpr('[a-z0-9 .,;&-]+', tut.tops, ignore.case=T))
tut.tops <- unlist(strsplit(tut.tops, split=',', fixed=T))
tut.tops <- gsub(' ', '', tut.tops)
}
if(length(tut.tops)==0) {
tops <- tops
}
tops <- c(tops, tut.tops)
# get programming languages
tut.l <- grep('languageTool', tut, value=T)
tut.l.2 <- grep('languagesTool', tut, value=T)
tut.l.3 <- grep('languagesTools', tut, value=T)
tut.l.4 <- grep('languageTools', tut, value=T)
tut.l <- c(tut.l, tut.l.2, tut.l.3, tut.l.4)
if(length(tut.l)==0) {
lang <- lang
} else {
tut.l <- unlist(strsplit(tut.l, split=':', fixed=T))
tut.l <- regmatches(tut.l, regexpr('[a-z0-9 .,;&-]+', tut.l, ignore.case=T))
tut.l <- unlist(strsplit(tut.l, split=',', fixed=T))
tut.l <- gsub(' ', '', tut.l)
}
if(length(tut.l)==0) {
lang <- lang
}
lang <- c(lang, tut.l)
}
unique(lang)
writeLines(unique(tops), '/Users/clunch/Desktop/tutorial_topics.txt')
writeLines(unique(lang), '/Users/clunch/Desktop/tutorial_langs.txt')
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://api.track.toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2023-12-20', until='2023-12-31'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://api.track.toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2023-12-20', until='2023-12-31'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://api.track.toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2023-12-20', until='2023-12-31'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://api.track.toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2023-12-20', until='2023-12-31'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
load("~/GitHub/NEON-utilities/neonUtilities/R/sysdata.rda")
write.table(shared_aquatic, '/Users/clunch/Desktop/shared_aquatic.csv', quote=F, sep=',', row.names=F)
load("~/GitHub/NEON-utilities/neonUtilities/R/sysdata.rda")
write.table(chem_bundles, '/Users/clunch/Desktop/chem_bundles.csv', sep=',', quote=F, row.names=F)
write.table(other_bundles, '/Users/clunch/Desktop/other_bundles.csv', sep=',', quote=F, row.names=F)
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://api.track.toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2023-12-20', until='2023-12-31'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(restR2)
p <- get.parser()
p <- get.parser()
p[grep('ELEMENT', p$parserValidation),]
taxa <- p[grep('ELEMENT', p$parserValidation),]
View(taxa)
# get pub workbooks
wbfiles <- list.files('/Users/clunch/GitHub/definitional-data/pubWBs/', include.dirs=F)
wbfiles
wbfiles <- wbfiles[grep('.txt$, wbfiles')]
wbfiles <- wbfiles[grep('.txt$', wbfiles)]
# get pub workbooks
wbfiles <- list.files('/Users/clunch/GitHub/definitional-data/pubWBs/',
include.dirs=F, full.names=T)
wbfiles <- wbfiles[grep('.txt$', wbfiles)]
i <- 4
wb <- read.delim(wbfiles[i])
length(grep('TAXONOMY', wb$ingestFieldSource))
nrow(wb)
wbt <- wb[grep('TAXONOMY', wb$ingestFieldSource),]
unique(wbt$table)
# read each workbook and (1) look for taxon fields, (2) check whether both code and name are present
tf <- character()
ti <- "alg_taxonomyProcessed_pub"
wbti <- wbt[which(wbt$table==ti),]
View(wbti)
wbti.inputs <- wbti$inputs
# read each workbook and (1) look for taxon fields, (2) check whether both code and name are present
# makes list of tables that *don't* have both code and name
tf <- character()
for(i in 1:length(wbfiles)) {
wb <- read.delim(wbfiles[i])
if(length(grep('TAXONOMY', wb$ingestFieldSource))==0) {
next
}
wbt <- wb[grep('TAXONOMY', wb$ingestFieldSource),]
for(ti in unique(wbt$table)) {
wbti <- wbt[which(wbt$table==ti),]
wbti.inputs <- wbti$inputs
if(!'scientificName' %in% wbti.inputs) {
tf <- c(tf, ti)
} else {
if('acceptedTaxonID' %in% wbti.inputs | 'taxonID' %in% wbti.inputs) {
next
}
else {
tf <- c(tf, ti)
}
}
}
}
tf
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://api.track.toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2023-12-20', until='2023-12-31'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
load("~/GitHub/NEON-utilities/neonUtilities/R/sysdata.rda")
Sys.setenv(PUB_TABLES = "http://prod-os-ds-1.ci.neoninternal.org:8080/osDataService/pub-tables")
Sys.setenv(NU_REPO = "/Users/clunch/GitHub/NEON-utilities")
source("~/GitHub/NEON-utilities/neonUtilities/data-raw/update_table_types.R")
library(devtools)
setwd("/Users/clunch/GitHub/NEON-utilities/neonUtilities")
source("~/GitHub/NEON-utilities/neonUtilities/data-raw/update_table_types.R")
urlchecker::url_check('.')
build()
install.packages('fasttime')
library(devtools)
library(urlchecker)
library(neonUtilities)
setwd("~/GitHub/NEON-OS-data-processing/neonOS")
install('.')
library(neonOS)
install.packages('vroom')
# run these lines every time
library(vroom)
vroom('/Users/clunch/Desktop/vroomy/')
vroom('/Users/clunch/Desktop/vroomy')
?vroom
vroom(list.files('/Users/clunch/Desktop/vroomy', full.names=T))
vroom_write(vroom(list.files("/Users/clunch/Desktop/vroomy", full.names=T), guess_max=Inf),
"/Users/clunch/Desktop/output_example.csv", delim=",", quote="needed")
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://api.track.toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
#           query=list(user_agent="clunch", workspace_id=wkid, since='2023-12-20', until='2023-12-31'))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
